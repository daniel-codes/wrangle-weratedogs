# Data Wrangling with WeRateDogs

The focus of this project is to create a tidy dataset consisting of tweet data from WeRateDogs (Twitter @dog_rates) and associated dog breed predictions from an image processing deep learning model. Additionally, the Python Tweepy library is used query the Twitter API and extract supplemental data. The WeRateDogs account gives a rating to peopleâ€™s dogs using a humorous commentary and rating system (e.g. 7/10, 11/10, 13/10, etc.). The focus of the data analysis is on dog ratings and popularity (retweet and favorite counts) and how they relate to dog breed and DoggoLingo.

## Getting Started

Cloning the git repository and installing the provided packages will help you get a copy of the project up and running on your local machine. The analysis for this project was performed using Jupyter Notebook (.ipynb) and the packages were managed using the Ananconda platform. 

```
https://github.com/daniel-codes/wrangle-weratedogs.git
pip install -r /path/to/requirements.txt
```

File Description:
- act_report.pdf - Summary report of the data wrangling and analysis process
- image-predictions.tsv - Deep learning image prediction data for the Twitter dataset
- twitter_archive_enhanced.csv - The WeRateDogs Twitter archive
- wrangle_act.ipynb - Jupyter Notebook for this project including exploratory data analysis and price prediction
- requirements.txt - packages used to perform this analysis

## Authors

- **Daniel Cummings** - [daniel-codes](https://github.com/daniel-codes)

## Acknowledgments

This project was performed as part of the Udacity Data Analyst Nanodegree program. 